<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="es">
<head>
    <title>SciMAT report - subperiod 2015-2020 - cluster ATTENTION MECHANISM</title>
  </head>
  <body>
    <h1>SciMAT report - subperiod 2015-2020 - cluster ATTENTION MECHANISM</h1>
    <hr/>
    <h2>Cluster info:</h2>
    <ul>
      <li>Name: ATTENTION MECHANISM</li>
      <li>Density: 6.48</li>
      <li>Densisty range: 0.86</li>
      <li>Centrality: 1.36</li>
      <li>Centrality range: 0.14</li>
    </ul>
    <h2>Cluster network:</h2>
<img alt="Cluster network" src="images/clusterNetwork-period5-cluster7.png" width="800" />
    <h2>Internal links:</h2>
      <table border="1" summary="this table shows the internal links of the cluster ATTENTION MECHANISM of the period 2015-2020">
        <caption><em>Internal links</em></caption>
        <tr>
          <td>Node A</td>
          <td>Node B</td>
          <td>Weight</td>
        </tr>
        <tr>
          <td>ATTENTION MECHANISM</td>
          <td>SEQ2SEQ</td>
          <td>0.15</td>
        </tr>
        <tr>
          <td>ATTENTION MECHANISM</td>
          <td>END-TO-END</td>
          <td>0.04</td>
        </tr>
      </table>
    <h2>External links:</h2>
      <table border="1" summary="this table shows the external links of the cluster ATTENTION MECHANISM of the period 2015-2020">
        <caption><em>External links</em></caption>
        <tr>
          <td>Node A</td>
          <td>Cluster node A</td>
          <td>Node B</td>
          <td>Cluster node B</td>
          <td>Weight</td>
        </tr>
        <tr>
          <td>TEXT RECOGNITION</td>
          <td>DNN</td>
          <td>ATTENTION MECHANISM</td>
          <td>ATTENTION MECHANISM</td>
          <td>0</td>
        </tr>
        <tr>
          <td>CNN</td>
          <td>DNN</td>
          <td>ATTENTION MECHANISM</td>
          <td>ATTENTION MECHANISM</td>
          <td>0</td>
        </tr>
        <tr>
          <td>NUMERAL RECOGNITION</td>
          <td>DNN</td>
          <td>ATTENTION MECHANISM</td>
          <td>ATTENTION MECHANISM</td>
          <td>0</td>
        </tr>
        <tr>
          <td>ATTENTION MECHANISM</td>
          <td>ATTENTION MECHANISM</td>
          <td>MATH RECOGNITION</td>
          <td>SEGMENTATION</td>
          <td>0.04</td>
        </tr>
        <tr>
          <td>ATTENTION MECHANISM</td>
          <td>ATTENTION MECHANISM</td>
          <td>AUTOENCODER</td>
          <td>WRITER IDENTIFICATION</td>
          <td>0.03</td>
        </tr>
        <tr>
          <td>TEXT RECOGNITION</td>
          <td>DNN</td>
          <td>SEQ2SEQ</td>
          <td>ATTENTION MECHANISM</td>
          <td>0</td>
        </tr>
        <tr>
          <td>CNN</td>
          <td>DNN</td>
          <td>SEQ2SEQ</td>
          <td>ATTENTION MECHANISM</td>
          <td>0</td>
        </tr>
        <tr>
          <td>RNN</td>
          <td>DNN</td>
          <td>SEQ2SEQ</td>
          <td>ATTENTION MECHANISM</td>
          <td>0.01</td>
        </tr>
        <tr>
          <td>SEQ2SEQ</td>
          <td>ATTENTION MECHANISM</td>
          <td>SENTENCE RECOGNITION</td>
          <td>HMM</td>
          <td>0.03</td>
        </tr>
        <tr>
          <td>TEXT RECOGNITION</td>
          <td>DNN</td>
          <td>END-TO-END</td>
          <td>ATTENTION MECHANISM</td>
          <td>0</td>
        </tr>
        <tr>
          <td>CNN</td>
          <td>DNN</td>
          <td>END-TO-END</td>
          <td>ATTENTION MECHANISM</td>
          <td>0</td>
        </tr>
        <tr>
          <td>NUMERAL RECOGNITION</td>
          <td>DNN</td>
          <td>END-TO-END</td>
          <td>ATTENTION MECHANISM</td>
          <td>0</td>
        </tr>
        <tr>
          <td>RNN</td>
          <td>DNN</td>
          <td>END-TO-END</td>
          <td>ATTENTION MECHANISM</td>
          <td>0.02</td>
        </tr>
      </table>
      <h2>Documents associated with the cluster</h2>
      <h3>coreDocuments (100 first documents with highest impact) </h3>
      <ul>
        <li>DOETSCH, P., ZEYER, A., NEY, H., Bidirectional Decoder Networks For Attention-based End-to-end Offline Handwriting Recognition. --- 0:null 361-366 (2016). 	Times cited: 9</li>
        <li>MICHAEL, J., LABAHN, R., GRUNING, T., ZOLLNER, J., Evaluating Sequence-to-sequence Models For Handwritten Text Recognition. --- null:null 1286-1293 (2019). 	Times cited: 1</li>
        <li>LUPINSKI, T., BELAÏD, A., ECHI, A.K., On The Use Of Attention Mechanism In A Seq2seq Based Approach For Off-line Handwritten Digit String Recognition. --- null:null 502-507 (2019). 	Times cited: 0</li>
        <li>WEI, H., LIU, C., ZHANG, H., BAO, F., GAO, G., End-to-end Model For Offline Handwritten Mongolian Word Recognition. --- 11839 LNAI:null 220-230 (2019). 	Times cited: 0</li>
      </ul>
      <h3>unionDocuments (100 first documents with highest impact) </h3>
      <ul>
        <li>ZHANG, J., DU, J., ZHANG, S., LIU, D., HU, Y., HU, J., WEI, S., DAI, L., Watch, Attend And Parse: An End-to-end Neural Network Based Approach To Handwritten Mathematical Expression Recognition. Pattern Recognition 71:null 196-206 (2017). 	Times cited: 46</li>
        <li>SUEIRAS, J., RUIZ, V., SANCHEZ, A., VÉLEZ, J.F., Offline Continuous Handwriting Recognition Using Sequence To Sequence Neural Networks. Neurocomputing 289:null 119-128 (2018). 	Times cited: 31</li>
        <li>LE, A.D., NAKAGAWA, M., Training An End-to-end System For Handwritten Mathematical Expression Recognition By Generated Patterns. --- 1:null 1056-1061 (2017). 	Times cited: 22</li>
        <li>SUN, Z., JIN, L., XIE, Z., FENG, Z., ZHANG, S., Convolutional Multi-directional Recurrent Network For Offline Handwritten Text Recognition. --- 0:null 240-245 (2016). 	Times cited: 14</li>
        <li>ZHAN, H., WANG, Q., LU, Y., Handwritten Digit String Recognition By Combination Of Residual Network And Rnn-ctc. --- 10639 LNCS:null 583-591 (2017). 	Times cited: 12</li>
        <li>DOETSCH, P., ZEYER, A., NEY, H., Bidirectional Decoder Networks For Attention-based End-to-end Offline Handwriting Recognition. --- 0:null 361-366 (2016). 	Times cited: 9</li>
        <li>WANG, W., ZHANG, J., DU, J., WANG, Z.-R., ZHU, Y., Denseran For Offline Handwritten Chinese Character Recognition. --- 2018-August:null 104-109 (2018). 	Times cited: 7</li>
        <li>LY, N.T., NGUYEN, C.T., NAKAGAWA, M., Training An End-to-end Model For Offline Handwritten Japanese Text Recognition By Generated Synthetic Patterns. --- 2018-August:null 74-79 (2018). 	Times cited: 6</li>
        <li>GAN, J., WANG, W., In-air Handwritten English Word Recognition Using Attention Recurrent Translator. Neural Computing And Applications 31:7 3155-3172 (2019). 	Times cited: 5</li>
        <li>LE, A.D., INDURKHYA, B., NAKAGAWA, M., Pattern Generation Strategies For Improving Recognition Of Handwritten Mathematical Expressions. Pattern Recognition Letters 128:null 255-262 (2019). 	Times cited: 3</li>
        <li>JIANG, H., WANG, D., ZHANG, Q., ZHAO, R., Motion Eavesdropper: Smartwatch-based Handwriting Recognition Using Deep Learning. --- null:null 145-153 (2019). 	Times cited: 1</li>
        <li>MICHAEL, J., LABAHN, R., GRUNING, T., ZOLLNER, J., Evaluating Sequence-to-sequence Models For Handwritten Text Recognition. --- null:null 1286-1293 (2019). 	Times cited: 1</li>
        <li>LIN, H., TAN, J., Application Of Deep Learning In Handwritten Mathematical Expressions Recognition. --- 12068 LNCS:null 137-147 (2020). 	Times cited: 0</li>
        <li>NEGI, A., RAO, A.M., Offline Handwritten Telugu Character Dataset And Recognition. --- null:null null-null (2019). 	Times cited: 0</li>
        <li>XU, Q., BAI, X., LIU, W., Multiple Comparative Attention Network For Offline Handwritten Chinese Character Recognition. --- null:null 595-600 (2019). 	Times cited: 0</li>
        <li>ELBAATI, A., HAMDI, Y., ALIMI, A.M., Handwriting Recognition Based On Temporal Order Restored By The End-to-end System. --- null:null 1231-1236 (2019). 	Times cited: 0</li>
        <li>WANG, J., DU, J., ZHANG, J., WANG, Z.-R., Multi-modal Attention Network For Handwritten Mathematical Expression Recognition. --- null:null 1181-1186 (2019). 	Times cited: 0</li>
        <li>LUPINSKI, T., BELAÏD, A., ECHI, A.K., On The Use Of Attention Mechanism In A Seq2seq Based Approach For Off-line Handwritten Digit String Recognition. --- null:null 502-507 (2019). 	Times cited: 0</li>
        <li>WEI, H., LIU, C., ZHANG, H., BAO, F., GAO, G., End-to-end Model For Offline Handwritten Mongolian Word Recognition. --- 11839 LNAI:null 220-230 (2019). 	Times cited: 0</li>
        <li>HASAN, A.H., OMAR, K., NASRUDIN, M.F., Multi-classifier Jawi Handwritten Sub-word Recognition. International Journal On Advanced Science, Engineering And Information Technology 8:4-2 1528-1533 (2018). 	Times cited: 0</li>
      </ul>
  </body>
</html>
